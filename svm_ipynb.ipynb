{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM - Diabetic Retinopathy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# io related\n",
    "# from skimage.io import imread\n",
    "import os\n",
    "from glob import glob\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from skimage import io, transform\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(base_location = 'F:/UNSW/2022/T2_2022/COMP9417/Project/Data/train.zip.001/train'):\n",
    "\n",
    "    training_data_name = \"train_1\"\n",
    "    train_data_dir = base_location + '/train'\n",
    "    train_label_file = base_location + '/trainLabels.csv'\n",
    "\n",
    "    # Load image mapping\n",
    "    retina_df = pd.read_csv(train_label_file)\n",
    "    # Get patient ID\n",
    "    retina_df['PatientId'] = retina_df['image'].map(lambda x: x.split('_')[0])\n",
    "    # Get image path\n",
    "    retina_df['path'] = retina_df['image'].map(lambda x: train_data_dir + '/' + x + '.jpeg')\n",
    "    # See if data exists in training data set\n",
    "    retina_df['exists'] = retina_df['path'].map(os.path.exists)\n",
    "    print(retina_df['exists'].sum(), 'images found of', retina_df.shape[0], 'total')\n",
    "\n",
    "    # Left right eye categorical variable\n",
    "    # 1 is left eye, 0 is right eye\n",
    "    retina_df['eye'] = retina_df['image'].map(lambda x: 1 if x.split('_')[-1]=='left' else 0)\n",
    "\n",
    "    # Remove NA, and keep only the 'existing' images \n",
    "    retina_df.dropna(inplace = True)\n",
    "    retina_df = retina_df[retina_df['exists']]\n",
    "\n",
    "    # Split traing and valid sets\n",
    "    rr_df = retina_df[['PatientId', 'level']].drop_duplicates()\n",
    "    \n",
    "    train_ids, valid_ids = train_test_split(rr_df['PatientId'], \n",
    "                                    test_size = 0.25, \n",
    "                                    random_state = 2018,\n",
    "                                    stratify = rr_df['level'])\n",
    "                                    \n",
    "    raw_train_df = retina_df[retina_df['PatientId'].isin(train_ids)]\n",
    "    valid_df = retina_df[retina_df['PatientId'].isin(valid_ids)]\n",
    "    print('Pre-balance: train', raw_train_df.shape[0], 'validation', valid_df.shape[0])\n",
    "    \n",
    "    # balance size variance in each class\n",
    "    #train_df = raw_train_df.groupby(['level', 'eye']).apply(lambda x: x.sample(75, replace = True)).reset_index(drop = True)                                                   \n",
    "    #print('Post-balance: train', train_df.shape[0], 'validation', valid_df.shape[0])\n",
    "\n",
    "    return raw_train_df, valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class retinaDataset(Dataset):\n",
    "\n",
    "    def __init__(self, transforms=None, image_size = 192):\n",
    "        'Initialization'\n",
    "        self.image_size = image_size\n",
    "        self.transforms = transforms        \n",
    "        self.train_df, self.valid_df = load_datasets()\n",
    "        \n",
    "        self.train_df.reset_index(drop = True, inplace = True)\n",
    "        self.valid_df.reset_index(drop = True, inplace = True)\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.train_df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        \n",
    "        img_path = self.train_df[\"path\"][index]\n",
    "        \n",
    "        # print(img_path)\n",
    "\n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, torch.tensor(self.train_df.iloc[index].level)\n",
    "    \n",
    "    def testLen(self):\n",
    "        return len(self.valid_df)\n",
    "    def getTest(self, index):\n",
    "        #gets test set \n",
    "        img_path = self.valid_df[\"path\"][index]\n",
    "        \n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        if(self.transforms):\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, torch.tensor(self.valid_df.iloc[index].level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_results(xTrain, yTrain, xTest, yTest, train_flag = True):\n",
    "    num_dec_point = 3\n",
    "    #train_flag = True\n",
    "\n",
    "    # generate predictions\n",
    "    y_pred = svm.predict(xTest)\n",
    "\n",
    "    if train_flag:\n",
    "        y_train_pred = svm.predict(xTrain) \n",
    "        print('Model Training accuracy is: ', accuracy_score(yTrain, y_train_pred))\n",
    "\n",
    "    # calculate testing accuracy\n",
    "    accuracy = accuracy_score(yTest, y_pred)\n",
    "    print('Model Testing accuracy is: ', accuracy)\n",
    "\n",
    "    p_mic, r_mic, f1_mic, _ = precision_recall_fscore_support(yTest, \n",
    "                            y_pred,\n",
    "                            average='micro',\n",
    "                            warn_for=())\n",
    "    p_mac, r_mac, f1_mac, _ = precision_recall_fscore_support(yTest, \n",
    "                        y_pred,\n",
    "                        average='macro',\n",
    "                        warn_for=())\n",
    "    print('micro acc,prec,rec,f1: ',round(accuracy,num_dec_point), round(p_mic,num_dec_point), round(r_mic,num_dec_point), round(f1_mic,num_dec_point),sep=\"\\t\")\n",
    "    print('macro prec,rec,f1: ',round(p_mac,num_dec_point), round(r_mac,num_dec_point), round(f1_mac,num_dec_point),sep=\"\\t\")\n",
    "    print('Confusion Matrix is: ', confusion_matrix(yTest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8408 images found of 35126 total\n",
      "Pre-balance: train 6512 validation 2318\n"
     ]
    }
   ],
   "source": [
    "image_size = 192\n",
    "\n",
    "my_transforms = transforms.Compose([\n",
    "    transforms.Resize((image_size,image_size)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = retinaDataset(transforms=my_transforms, image_size = image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size:  480 testing size:  120\n",
      "0: train /480\n",
      "10: train /480\n",
      "20: train /480\n",
      "30: train /480\n",
      "40: train /480\n",
      "50: train /480\n",
      "60: train /480\n",
      "70: train /480\n",
      "80: train /480\n",
      "90: train /480\n",
      "100: train /480\n",
      "110: train /480\n",
      "120: train /480\n",
      "130: train /480\n",
      "140: train /480\n",
      "150: train /480\n",
      "160: train /480\n",
      "170: train /480\n",
      "180: train /480\n",
      "190: train /480\n",
      "200: train /480\n",
      "210: train /480\n",
      "220: train /480\n",
      "230: train /480\n",
      "240: train /480\n",
      "250: train /480\n",
      "260: train /480\n",
      "270: train /480\n",
      "280: train /480\n",
      "290: train /480\n",
      "300: train /480\n",
      "310: train /480\n",
      "320: train /480\n",
      "330: train /480\n",
      "340: train /480\n",
      "350: train /480\n",
      "360: train /480\n",
      "370: train /480\n",
      "380: train /480\n",
      "390: train /480\n",
      "400: train /480\n",
      "410: train /480\n",
      "420: train /480\n",
      "430: train /480\n",
      "440: train /480\n",
      "450: train /480\n",
      "460: train /480\n",
      "470: train /480\n",
      "0: test /120\n",
      "10: test /120\n",
      "20: test /120\n",
      "30: test /120\n",
      "40: test /120\n",
      "50: test /120\n",
      "60: test /120\n",
      "70: test /120\n",
      "80: test /120\n",
      "90: test /120\n",
      "100: test /120\n",
      "110: test /120\n",
      "Completed.\n"
     ]
    }
   ],
   "source": [
    "#shuffle dataset\n",
    "import random\n",
    "\n",
    "n = 600 #number of total datasets\n",
    "ratio = 0.8 #training:testing\n",
    "#total = random.sample(range(len(dataset)), n)\n",
    "training_number = int(n * ratio)\n",
    "testing_number = n - training_number\n",
    "\n",
    "training_items = random.sample(range(len(dataset)), training_number)\n",
    "testing_items = random.sample(range(dataset.testLen()), testing_number)\n",
    "print('training size: ', training_number, 'testing size: ', testing_number)\n",
    "\n",
    "xTrain = []\n",
    "yTrain = []\n",
    "xTest = []\n",
    "yTest = []\n",
    "\n",
    "# Populate xTrain yTrain\n",
    "for index, i in enumerate(training_items):#range(100):#len(dataset)):\n",
    "    if index % 10 == 0:\n",
    "        print(str(index) + ': train /' + str(len(training_items)))\n",
    "    item, label = dataset.__getitem__(i)\n",
    "    oneD = item.flatten()\n",
    "    xTrain.append(oneD)\n",
    "    # Append labels\n",
    "    yTrain.append(label)\n",
    "    \n",
    "# Populate xTest yTest\n",
    "for index, i in enumerate(testing_items):#range(100):# range(dataset.testLen()):\n",
    "    if index % 10 == 0:\n",
    "        print(str(index) + ': test /' + str(len(testing_items)))\n",
    "    item, label = dataset.getTest(i)\n",
    "    oneD = item.flatten()\n",
    "    # Append flatten image matrix\n",
    "    xTest.append(oneD)\n",
    "    # Append labels\n",
    "    yTest.append(label) \n",
    "    \n",
    "xTrain = np.vstack(xTrain)\n",
    "yTrain = np.array(yTrain)\n",
    "xTest = np.vstack(xTest)\n",
    "yTest = np.array(yTest)\n",
    "\n",
    "print('Completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and Predicting SVM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train 480, 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "Model Training accuracy is:  0.9979166666666667\n",
      "Model Testing accuracy is:  0.625\n",
      "micro acc,prec,rec,f1: \t0.625\t0.625\t0.625\t0.625\n",
      "macro prec,rec,f1: \t0.19\t0.194\t0.192\n",
      "Confusion Matrix is:  [[72  7 11  1  1]\n",
      " [ 8  0  2  0  0]\n",
      " [12  1  3  0  0]\n",
      " [ 1  0  1  0  0]\n",
      " [ 0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel='linear', C=0.1, gamma='auto', probability=False) #faster when probability = False\n",
    "\n",
    "# fit model\n",
    "svm.fit(xTrain, yTrain)\n",
    "print(svm)\n",
    "\n",
    "generate_results(xTrain, yTrain, xTest, yTest, train_flag = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training = 720, testing 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "Model Training accuracy is:  0.9986111111111111\n",
      "Model Testing accuracy is:  0.3611111111111111\n",
      "micro acc,prec,rec,f1: \t0.361\t0.361\t0.361\t0.361\n",
      "macro prec,rec,f1: \t0.271\t0.269\t0.231\n",
      "Confusion Matrix is:  [[44 25 24 17 13]\n",
      " [ 4 12  6  1  3]\n",
      " [ 2  7  8  3  1]\n",
      " [ 0  4  1  1  1]\n",
      " [ 1  1  1  0  0]]\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel='linear', C=0.1, gamma='auto', probability=False) #faster when probability = False\n",
    "\n",
    "# fit model\n",
    "svm.fit(xTrain, yTrain)\n",
    "print(svm)\n",
    "\n",
    "generate_results(xTrain, yTrain, xTest, yTest, train_flag = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "Model Training accuracy is:  0.2013888888888889\n",
      "Model Testing accuracy is:  0.11666666666666667\n",
      "micro acc,prec,rec,f1: \t0.117\t0.117\t0.117\t0.117\n",
      "macro prec,rec,f1: \t0.023\t0.2\t0.042\n",
      "Confusion Matrix is:  [[  0   0 123   0   0]\n",
      " [  0   0  26   0   0]\n",
      " [  0   0  21   0   0]\n",
      " [  0   0   7   0   0]\n",
      " [  0   0   3   0   0]]\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel='poly', C=0.1, gamma='auto', probability=False) #faster when probability = False\n",
    "\n",
    "# fit model\n",
    "svm.fit(xTrain, yTrain)\n",
    "print(svm)\n",
    "\n",
    "generate_results(xTrain, yTrain, xTest, yTest, train_flag = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "Model Training accuracy is:  1.0\n",
      "Model Testing accuracy is:  0.2875\n",
      "micro acc,prec,rec,f1: \t0.288\t0.288\t0.288\t0.288\n",
      "macro prec,rec,f1: \t0.204\t0.329\t0.171\n",
      "Confusion Matrix is:  [[19 17  7  9  9]\n",
      " [ 5  2  0  2  0]\n",
      " [ 3  1  1  3  1]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  0  0  1]]\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel='linear', C=1, gamma='auto', probability=False) #faster when probability = False\n",
    "\n",
    "# fit model\n",
    "svm.fit(xTrain, yTrain)\n",
    "print(svm)\n",
    "\n",
    "generate_results(xTrain, yTrain, xTest, yTest, train_flag = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.5, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "Model Training accuracy is:  1.0\n",
      "Model Testing accuracy is:  0.2875\n",
      "micro acc,prec,rec,f1: \t0.288\t0.288\t0.288\t0.288\n",
      "macro prec,rec,f1: \t0.204\t0.329\t0.171\n",
      "Confusion Matrix is:  [[19 17  7  9  9]\n",
      " [ 5  2  0  2  0]\n",
      " [ 3  1  1  3  1]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  0  0  1]]\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel='linear', C=0.5, gamma='auto', probability=False) #faster when probability = False\n",
    "\n",
    "# fit model\n",
    "svm.fit(xTrain, yTrain)\n",
    "print(svm)\n",
    "\n",
    "generate_results(xTrain, yTrain, xTest, yTest, train_flag = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "Model Training accuracy is:  0.996875\n",
      "Model Testing accuracy is:  0.2875\n",
      "micro acc,prec,rec,f1: \t0.288\t0.288\t0.288\t0.288\n",
      "macro prec,rec,f1: \t0.207\t0.329\t0.172\n",
      "Confusion Matrix is:  [[19 17  6 10  9]\n",
      " [ 5  2  0  2  0]\n",
      " [ 3  1  1  3  1]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  0  0  1]]\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel='linear', C=0.1, gamma='auto', probability=False) #faster when probability = False\n",
    "\n",
    "# fit model\n",
    "svm.fit(xTrain, yTrain)\n",
    "print(svm)\n",
    "\n",
    "generate_results(xTrain, yTrain, xTest, yTest, train_flag = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.01, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-28fb2fc8db12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mgenerate_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_flag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-5f528f6e0339>\u001b[0m in \u001b[0;36mgenerate_results\u001b[1;34m(xTrain, yTrain, xTest, yTest, train_flag)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtrain_flag\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0my_train_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model Training accuracy is: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    592\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    595\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_dense_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_dense_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobA_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobB_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvm_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msvm_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[0mdegree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m             cache_size=self.cache_size)\n\u001b[0m\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_sparse_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel='linear', C=0.01, gamma='auto', probability=False) #faster when probability = False\n",
    "\n",
    "# fit model\n",
    "svm.fit(xTrain, yTrain)\n",
    "print(svm)\n",
    "\n",
    "generate_results(xTrain, yTrain, xTest, yTest, train_flag = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
