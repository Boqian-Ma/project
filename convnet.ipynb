{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import train, evaluate, load_data_loaders, epoch_time\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import trange\n",
    "from functools import partial\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from models import LeNet\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # get some random training images\n",
    "# dataiter = iter(train_dataloader)\n",
    "# t_x, t_y = next(dataiter)\n",
    "# fig, axs = plt.subplots(2, 4, figsize = (16, 8))\n",
    "# for ax in axs.flatten():\n",
    "#     t_x, t_y = next(dataiter)\n",
    "#     ax.imshow(t_x[0].permute(1, 2, 0))\n",
    "#     ax.set_title('Severity {}'.format(int(t_y[0])))\n",
    "\n",
    "# len(axs.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_train(epochs, learning_rate, batch_size=1, num_workers=0, config=None):\n",
    "    # num_classes = 5\n",
    "\n",
    "    model = LeNet()\n",
    "\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = \"mps\"\n",
    "        model = nn.DataParallel(model)\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    train_dataloader, valid_dataloader = load_data_loaders(batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "    best_valid_loss = float('inf')\n",
    "\n",
    "    train_losses = []\n",
    "    validation_losses = []\n",
    "    train_accs = []\n",
    "    validation_accs = []\n",
    "\n",
    "    for epoch in trange(epochs, desc=\"Epochs\"):\n",
    "\n",
    "        start_time = time.monotonic()\n",
    "\n",
    "        train_loss, train_acc = train(model, train_dataloader, optimizer, criterion, device)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "\n",
    "        # if epoch % 5 == 0:\n",
    "        valid_loss, valid_acc = evaluate(model, valid_dataloader, criterion, device)\n",
    "\n",
    "        validation_losses.append(valid_loss)\n",
    "        validation_accs.append(valid_acc)\n",
    "\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), 'conv-model.pt')\n",
    "\n",
    "        end_time = time.monotonic()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "\n",
    "    # tune.report(loss=(valid_loss), accuracy=valid_acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8408 images found of 35126 total\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b04be2190c410988b68c877a4bc3e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5697d53fa0444ea59f40a7130cf57faf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/204 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3805bba3bcdc44ca9fdf450ee1bd8626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 4m 33s\n",
      "\tTrain Loss: inf | Train Acc: 70.74%\n",
      "\t Val. Loss: 0.963 |  Val. Acc: 69.44%\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "EPOCHS = 1\n",
    "main_train(EPOCHS, learning_rate, batch_size=32, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch-nightly')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f030abe0ee2620ffe6027ca94a5e9fde6f522103fa37946a83df3b836b867a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
